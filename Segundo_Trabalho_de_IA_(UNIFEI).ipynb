{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segundo Trabalho de IA (UNIFEI).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNdPo005M3MH6Wx1sRP8ce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GenoaroSJr/Cursos/blob/main/Segundo_Trabalho_de_IA_(UNIFEI).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BR8TC0RMvSK"
      },
      "source": [
        "#Segundo trabalho de Inteligencia Artificial:\n",
        "###Aprendizado de Máquina Supervisionado Classificatório\n",
        "\n",
        "**Banco de dados:** vehicle \n",
        "\n",
        "**Ténicas:** BernoulliNB & BaggingClassifier\n",
        "\n",
        "**Trabalho por:** Genoaro Soares Junior\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ0mFwMNOaPE"
      },
      "source": [
        "## Importanto bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij_t-bzFOewM"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef89asKJNhSe"
      },
      "source": [
        "## Importando e tratando dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LLoZcY9NfZO",
        "outputId": "d2f5b5c1-abf2-4eb2-a25c-aa586f6dd9b4"
      },
      "source": [
        "#Baixando dados;\n",
        "!wget \"https://github.com/valerio-unifei/UNIFEI-IA-Aulas/raw/main/benchmark-datasets.zip\" -O datasets.zip\n",
        "!unzip datasets.zip\n",
        "!rm datasets.zip"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-04 23:44:06--  https://github.com/valerio-unifei/UNIFEI-IA-Aulas/raw/main/benchmark-datasets.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/valerio-unifei/UNIFEI-IA-Aulas/main/benchmark-datasets.zip [following]\n",
            "--2021-07-04 23:44:07--  https://raw.githubusercontent.com/valerio-unifei/UNIFEI-IA-Aulas/main/benchmark-datasets.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1232196 (1.2M) [application/zip]\n",
            "Saving to: ‘datasets.zip’\n",
            "\n",
            "datasets.zip        100%[===================>]   1.17M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-07-04 23:44:07 (20.6 MB/s) - ‘datasets.zip’ saved [1232196/1232196]\n",
            "\n",
            "Archive:  datasets.zip\n",
            "replace led7digit.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: led7digit.csv           \n",
            "  inflating: letter.csv              \n",
            "  inflating: nursery.csv             \n",
            "  inflating: optdigits.csv           \n",
            "  inflating: page-blocks.csv         \n",
            "  inflating: penbased.csv            \n",
            "  inflating: satimage.csv            \n",
            "  inflating: shuttle.csv             \n",
            "  inflating: thyroid.csv             \n",
            "  inflating: titanic.csv             \n",
            "  inflating: vehicle.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlWHvGgMMuPa",
        "outputId": "2bab4007-593a-4306-a15a-928cfa7657db"
      },
      "source": [
        "#Selecionando tabela a ser utilizada;\n",
        "data = pd.read_csv(\"/content/vehicle.csv\")\n",
        "data.head().min()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compactness                    85\n",
              " Circularity                   41\n",
              " Distance_circularity          70\n",
              " Radius_ratio                 141\n",
              " Praxis_aspect_ratio           57\n",
              " Max_length_aspect_ratio        9\n",
              " Scatter_ratio                144\n",
              " Elongatedness                 32\n",
              " Praxis_rectangular            19\n",
              " Length_rectangular           143\n",
              " Major_variance               160\n",
              " Minor_variance               309\n",
              " Gyration_radius              127\n",
              " Major_skewness                63\n",
              " Minor_skewness                 6\n",
              " Minor_kurtosis                 9\n",
              " Major_kurtosis               180\n",
              " Hollows_ratio                183\n",
              " Class                       bus \n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi-_uXYHTDlQ",
        "outputId": "dcccdbd8-cfeb-4bf2-c7b9-4b8497287f50"
      },
      "source": [
        "data.head().max()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compactness                   104\n",
              " Circularity                   50\n",
              " Distance_circularity         106\n",
              " Radius_ratio                 209\n",
              " Praxis_aspect_ratio          103\n",
              " Max_length_aspect_ratio       52\n",
              " Scatter_ratio                207\n",
              " Elongatedness                 46\n",
              " Praxis_rectangular            23\n",
              " Length_rectangular           159\n",
              " Major_variance               241\n",
              " Minor_variance               635\n",
              " Gyration_radius              220\n",
              " Major_skewness               127\n",
              " Minor_skewness                14\n",
              " Minor_kurtosis                16\n",
              " Major_kurtosis               199\n",
              " Hollows_ratio                207\n",
              " Class                       van \n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWwHQNL0TTua"
      },
      "source": [
        "**Obs:** Avaliando a diferença de escla entre os valores, é possível observar que não há uma diferença significativa, portanto, não seria necessário fazer o Standardisation ou o Normalization. \n",
        "\n",
        "-- Tal procedimento será realizado após alguns passos pois a proposta exige."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMP5T_AYPkxw",
        "outputId": "5de91622-1b35-4610-e267-85f1a1f35447"
      },
      "source": [
        "#data.describe()\n",
        "data.info()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 846 entries, 0 to 845\n",
            "Data columns (total 19 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Compactness               846 non-null    int64 \n",
            " 1    Circularity              846 non-null    int64 \n",
            " 2    Distance_circularity     846 non-null    int64 \n",
            " 3    Radius_ratio             846 non-null    int64 \n",
            " 4    Praxis_aspect_ratio      846 non-null    int64 \n",
            " 5    Max_length_aspect_ratio  846 non-null    int64 \n",
            " 6    Scatter_ratio            846 non-null    int64 \n",
            " 7    Elongatedness            846 non-null    int64 \n",
            " 8    Praxis_rectangular       846 non-null    int64 \n",
            " 9    Length_rectangular       846 non-null    int64 \n",
            " 10   Major_variance           846 non-null    int64 \n",
            " 11   Minor_variance           846 non-null    int64 \n",
            " 12   Gyration_radius          846 non-null    int64 \n",
            " 13   Major_skewness           846 non-null    int64 \n",
            " 14   Minor_skewness           846 non-null    int64 \n",
            " 15   Minor_kurtosis           846 non-null    int64 \n",
            " 16   Major_kurtosis           846 non-null    int64 \n",
            " 17   Hollows_ratio            846 non-null    int64 \n",
            " 18   Class                    846 non-null    object\n",
            "dtypes: int64(18), object(1)\n",
            "memory usage: 125.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1B5HA9tQCwr"
      },
      "source": [
        "**Obs:** Não há dados faltantes no dataset, portanto, não é necessário fazer o tratamento desses dados. A classe do dataset é em valores categóricos, ou seja, são strings, para que o algoritmo possa fazer corretamente as contas necessárias, é preciso transformar esses valores em numéricos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8_MVVIIRVlw"
      },
      "source": [
        "#Separando entre classe e previsores;\n",
        "# x -> previsores; y -> classe\n",
        "x = data.iloc[:,0:18].values\n",
        "y = data.iloc[:,18].values"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OM7L9MDT5lq"
      },
      "source": [
        "#Será utilizado o LabelEncoder para fazer a transformação dos atributos categóricos;\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoder = label_encoder.fit_transform(y) \n",
        "# Os valores foram \"numerizados\", preservando os dados anteriores;\n",
        "##print(y_encoder)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLY8-ylIVULg"
      },
      "source": [
        "#Realizando o Standardisation\n",
        "scaler = StandardScaler()\n",
        "x_scaler = scaler.fit_transform(x)\n",
        "#print(x) Não escalonado\n",
        "#print(x_scaler) Escalonado"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3rikDysWOj9"
      },
      "source": [
        "**Obs:** Os dados de \"classe\" (y_encoder), não será escalonado pois não há sentido na operação, uma vez que os valores não representam um range de \"avaliação\" ou \"nota\" mas sim uma classificação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mb0DprjWjg2"
      },
      "source": [
        "## Iniciando os modelos de aprendizado de máquina supervisionado classificador\n",
        "\n",
        "\n",
        "\n",
        "> **Técnicas:** BernoulliNB & BaggingClassifier\n",
        ">\n",
        "> **Para os dados (já tratados):**\n",
        "> \n",
        "> (x_scaler, y_encoder)\n",
        ">\n",
        "> **Extra - x não escalonado:**\n",
        ">\n",
        "> (x, y_encoder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw6TnRstWfCo"
      },
      "source": [
        "### Para os dados tratados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVXT142zV7j8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76395d8-170d-41b2-e046-11ad02d82201"
      },
      "source": [
        "bernoulliUm = BernoulliNB()\n",
        "\n",
        "cv_results = cross_validate(bernoulliUm, x_scaler, y_encoder, cv=10, scoring=['accuracy', 'recall_macro', 'precision_macro'])\n",
        "\n",
        "accuracy_medio = sum(cv_results['test_accuracy'])/10\n",
        "recall_medio = sum(cv_results['test_recall_macro'])/10\n",
        "precision_medio = sum(cv_results['test_precision_macro'])/10\n",
        "\n",
        "print(\"Accuracy_medio: \", accuracy_medio)\n",
        "print(\"Recall_medio: \", recall_medio)\n",
        "print(\"Precision_medio: \", precision_medio)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy_medio:  0.4597759103641456\n",
            "Recall_medio:  0.46872294372294376\n",
            "Precision_medio:  0.5153259445953478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mdTpf1g289o",
        "outputId": "dfb115ba-eb1d-4a15-c764-63bcfe73f541"
      },
      "source": [
        "# Matriz de confusão.\n",
        "y_pred = bernoulliUm.fit(x_scaler,y_encoder)\n",
        "y_pred = bernoulliUm.predict(x_scaler)\n",
        "\n",
        "confusion_matrix(y_encoder, y_pred)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 46,  51,  19, 102],\n",
              "       [ 10,  57,  76,  69],\n",
              "       [  6,  45,  95,  71],\n",
              "       [  0,   4,   6, 189]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_978aWEWIiM",
        "outputId": "47eeee53-98a7-46c0-dc04-9e3773bafd36"
      },
      "source": [
        "baggingUm = BaggingClassifier()\n",
        "\n",
        "cv_results = cross_validate(baggingUm, x_scaler, y_encoder, cv=10, scoring=['accuracy', 'recall_macro', 'precision_macro'])\n",
        "\n",
        "accuracy_medio = sum(cv_results['test_accuracy'])/10\n",
        "recall_medio = sum(cv_results['test_recall_macro'])/10\n",
        "precision_medio = sum(cv_results['test_precision_macro'])/10\n",
        "\n",
        "print(\"Accuracy_medio: \", accuracy_medio)\n",
        "print(\"Recall_medio: \", recall_medio)\n",
        "print(\"Precision_medio: \", precision_medio)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy_medio:  0.7210364145658263\n",
            "Recall_medio:  0.7243156185919344\n",
            "Precision_medio:  0.7156272627095837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oavNHAIU4iMC",
        "outputId": "af1afe50-bc85-4108-b65a-1bbad332bcbf"
      },
      "source": [
        "# Matriz de confusão.\n",
        "y_pred = baggingUm.fit(x_scaler,y_encoder)\n",
        "y_pred = baggingUm.predict(x_scaler)\n",
        "\n",
        "confusion_matrix(y_encoder, y_pred)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[218,   0,   0,   0],\n",
              "       [  2, 207,   3,   0],\n",
              "       [  1,   8, 207,   1],\n",
              "       [  0,   0,   0, 199]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLcbiby3Wnhh"
      },
      "source": [
        "### Para x não escalonado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCdimJO6LlIK",
        "outputId": "6f21e38a-7274-414a-a754-c2e7e7515122"
      },
      "source": [
        "bernoulliDois = BernoulliNB()\n",
        "\n",
        "cv_results = cross_validate(bernoulliDois, x, y_encoder, cv=10, scoring=['accuracy', 'recall_macro', 'precision_macro'])\n",
        "\n",
        "accuracy_medio = sum(cv_results['test_accuracy'])/10\n",
        "recall_medio = sum(cv_results['test_recall_macro'])/10\n",
        "precision_medio = sum(cv_results['test_precision_macro'])/10\n",
        "\n",
        "print(\"Accuracy_medio: \", accuracy_medio)\n",
        "print(\"Recall_medio: \", recall_medio)\n",
        "print(\"Precision_medio: \", precision_medio)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy_medio:  0.25894957983193273\n",
            "Recall_medio:  0.25486557302346774\n",
            "Precision_medio:  0.20829997936076222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCAGDn6-47mm",
        "outputId": "ef3f76b8-590d-4b2f-e9af-cad2a520804d"
      },
      "source": [
        "# Matriz de confusão.\n",
        "y_pred = bernoulliDois.fit(x_scaler,y_encoder)\n",
        "y_pred = bernoulliDois.predict(x_scaler)\n",
        "\n",
        "confusion_matrix(y_encoder, y_pred)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 46,  51,  19, 102],\n",
              "       [ 10,  57,  76,  69],\n",
              "       [  6,  45,  95,  71],\n",
              "       [  0,   4,   6, 189]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHjymbhsXFY2",
        "outputId": "02025e90-6ce3-4d0a-aec5-41cabb6cd09f"
      },
      "source": [
        "baggingDois = BaggingClassifier()\n",
        "\n",
        "cv_results = cross_validate(baggingDois, x, y_encoder, cv=10, scoring=['accuracy', 'recall_macro', 'precision_macro'])\n",
        "\n",
        "accuracy_medio = sum(cv_results['test_accuracy'])/10\n",
        "recall_medio = sum(cv_results['test_recall_macro'])/10\n",
        "precision_medio = sum(cv_results['test_precision_macro'])/10\n",
        "\n",
        "print(\"Accuracy_medio: \", accuracy_medio)\n",
        "print(\"Recall_medio: \", recall_medio)\n",
        "print(\"Precision_medio: \", precision_medio)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy_medio:  0.7444957983193278\n",
            "Recall_medio:  0.7475099681020734\n",
            "Precision_medio:  0.7397084544412136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNpfWox05AyG",
        "outputId": "49efd548-851c-47e4-ce48-77e5604d334c"
      },
      "source": [
        "# Matriz de confusão.\n",
        "y_pred = bernoulliDois.fit(x_scaler,y_encoder)\n",
        "y_pred = bernoulliDois.predict(x_scaler)\n",
        "\n",
        "confusion_matrix(y_encoder, y_pred)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 46,  51,  19, 102],\n",
              "       [ 10,  57,  76,  69],\n",
              "       [  6,  45,  95,  71],\n",
              "       [  0,   4,   6, 189]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACEuXnWG-rLY"
      },
      "source": [
        "**Obs:** Contrário do que se esperava no começo, o escalonamento dos dados deu uma diferença significativa para o método BernoulliNB, deixando o método, que não é bom para esse tipo de dado, ainda pior. No caso Bagging, a diferença entre não escalonado e escalonado não é significativa."
      ]
    }
  ]
}